#!/usr/bin/env python3
"""
TimescaleDB Hypertable è¿ç§»è„šæœ¬
å°† fills è¡¨è¿ç§»åˆ° TimescaleDB hypertable ä»¥è·å¾—æ—¶åºæ•°æ®ä¼˜åŒ–
"""
import asyncio
import asyncpg
import os
from datetime import datetime


async def migrate_to_hypertable():
    """å°† fills è¡¨è¿ç§»åˆ° TimescaleDB hypertable"""
    # æ•°æ®åº“é…ç½®
    db_config = {
        'user': os.getenv('TIMESCALEDB_USER', 'postgres'),
        'password': os.getenv('TIMESCALEDB_PASSWORD', 'postgres'),
        'host': os.getenv('TIMESCALEDB_HOST', '127.0.0.1'),
        'port': int(os.getenv('TIMESCALEDB_PORT', 5432)),
        'database': os.getenv('TIMESCALEDB_DATABASE', 'hyperliquid_analysis'),
        'command_timeout': 600  # 10 åˆ†é’Ÿè¶…æ—¶
    }

    print("=" * 60)
    print("TimescaleDB Hypertable è¿ç§»å·¥å…·")
    print("=" * 60)

    try:
        # åˆ›å»ºè¿æ¥
        print("\nğŸ“¡ è¿æ¥æ•°æ®åº“...")
        conn = await asyncpg.connect(**db_config)
        print("   âœ“ è¿æ¥æˆåŠŸ")

        # 1. æ£€æŸ¥å½“å‰çŠ¶æ€
        print("\n1ï¸âƒ£  æ£€æŸ¥å½“å‰çŠ¶æ€...")
        fills_count = await conn.fetchval("SELECT COUNT(*) FROM fills")
        print(f"   fills è¡¨: {fills_count:,} æ¡è®°å½•")

        is_hypertable = await conn.fetchval("""
            SELECT EXISTS(
                SELECT 1 FROM timescaledb_information.hypertables
                WHERE hypertable_name = 'fills'
            )
        """)

        if is_hypertable:
            print("   â„¹ï¸  fills å·²ç»æ˜¯ hypertableï¼Œæ— éœ€è¿ç§»")
            await conn.close()
            return True

        # æ£€æŸ¥ä¸»é”®é¡ºåº
        pk_columns = await conn.fetch("""
            SELECT a.attname
            FROM pg_index i
            JOIN pg_attribute a ON a.attrelid = i.indrelid
                AND a.attnum = ANY(i.indkey)
            WHERE i.indrelid = 'fills'::regclass
                AND i.indisprimary
            ORDER BY array_position(i.indkey, a.attnum)
        """)

        pk_order = [r['attname'] for r in pk_columns]
        print(f"   å½“å‰ä¸»é”®: ({', '.join(pk_order)})")

        # 2. é‡å‘½åç°æœ‰è¡¨
        print("\n2ï¸âƒ£  é‡å‘½åç°æœ‰è¡¨...")
        await conn.execute("ALTER TABLE fills RENAME TO fills_backup")
        print("   âœ“ å·²é‡å‘½åä¸º fills_backup")

        # 3. åˆ›å»ºæ–°è¡¨
        print("\n3ï¸âƒ£  åˆ›å»ºæ–°è¡¨...")
        await conn.execute("""
            CREATE TABLE fills (
                id BIGINT NOT NULL,
                address VARCHAR(42) NOT NULL,
                time TIMESTAMPTZ NOT NULL,
                coin VARCHAR(20),
                side VARCHAR(1),
                price DECIMAL(20, 8),
                size DECIMAL(20, 4),
                closed_pnl DECIMAL(20, 8),
                fee DECIMAL(20, 8),
                hash VARCHAR(66),
                PRIMARY KEY (time, address, id)
            )
        """)
        print("   âœ“ æ–°è¡¨å·²åˆ›å»ºï¼ˆä¸»é”®: time, address, idï¼‰")

        # 4. è½¬æ¢ä¸º hypertable
        print("\n4ï¸âƒ£  è½¬æ¢ä¸º hypertable...")
        await conn.execute("""
            SELECT create_hypertable('fills', 'time',
                chunk_time_interval => INTERVAL '7 days',
                if_not_exists => true
            )
        """)
        print("   âœ“ å·²è½¬æ¢ä¸º hypertable")

        # 5. æ‰¹é‡å¤åˆ¶æ•°æ®
        print("\n5ï¸âƒ£  æ‰¹é‡å¤åˆ¶æ•°æ®ï¼ˆ1.4M+ æ¡è®°å½•ï¼Œé¢„è®¡ 3-5 åˆ†é’Ÿï¼‰...")
        print("   ä½¿ç”¨æ‰¹é‡ INSERT è¿›è¡Œæ•°æ®è¿ç§»...")

        start_time = datetime.now()

        # ä½¿ç”¨æ‰¹é‡æŸ¥è¯¢å’Œæ’å…¥
        batch_size = 50000
        offset = 0

        while True:
            rows = await conn.fetch(f"""
                SELECT id, address, time, coin, side, price, size, closed_pnl, fee, hash
                FROM fills_backup
                ORDER BY time, address, id
                LIMIT {batch_size} OFFSET {offset}
            """)

            if not rows:
                break

            # æ‰¹é‡æ’å…¥
            await conn.executemany("""
                INSERT INTO fills (id, address, time, coin, side, price, size, closed_pnl, fee, hash)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
            """, [
                (r['id'], r['address'], r['time'], r['coin'], r['side'],
                 r['price'], r['size'], r['closed_pnl'], r['fee'], r['hash'])
                for r in rows
            ])

            offset += batch_size
            progress = min(offset * 100 // fills_count, 100)
            print(f"   è¿›åº¦: {offset:,} / {fills_count:,} ({progress}%)", end='\r')

            if len(rows) < batch_size:
                break

        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"\n   âœ“ æ•°æ®å¤åˆ¶å®Œæˆ: {offset:,} æ¡ ({elapsed:.1f}ç§’)")

        # 6. éªŒè¯æ•°æ®
        print("\n6ï¸âƒ£  éªŒè¯æ•°æ®...")
        new_count = await conn.fetchval("SELECT COUNT(*) FROM fills")
        backup_count = await conn.fetchval("SELECT COUNT(*) FROM fills_backup")

        if new_count != backup_count:
            print(f"   âœ— æ•°æ®ä¸ä¸€è‡´: backup={backup_count:,}, new={new_count:,}")
            raise Exception("æ•°æ®éªŒè¯å¤±è´¥")

        print(f"   âœ“ æ•°æ®å®Œæ•´: {new_count:,} æ¡è®°å½•")

        # 7. åˆ›å»ºç´¢å¼•
        print("\n7ï¸âƒ£  åˆ›å»ºç´¢å¼•...")
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_fills_address_time
            ON fills(address, time DESC)
        """)
        print("   âœ“ ç´¢å¼•å·²åˆ›å»º")

        # 8. éªŒè¯ hypertable
        print("\n8ï¸âƒ£  éªŒè¯ hypertable...")
        is_hypertable = await conn.fetchval("""
            SELECT EXISTS(
                SELECT 1 FROM timescaledb_information.hypertables
                WHERE hypertable_name = 'fills'
            )
        """)

        if not is_hypertable:
            raise Exception("è¡¨æœªæˆåŠŸè½¬æ¢ä¸º hypertable")

        print("   âœ“ ç¡®è®¤ä¸º hypertable")

        # 9. æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
        print("\n9ï¸âƒ£  æœ€ç»ˆçŠ¶æ€:")

        # æŸ¥è¯¢è¡¨å¤§å°
        total_size = await conn.fetchval("""
            SELECT pg_size_pretty(pg_total_relation_size('fills'::regclass))
        """)

        backup_size = await conn.fetchval("""
            SELECT pg_size_pretty(pg_total_relation_size('fills_backup'::regclass))
        """)

        # æŸ¥è¯¢åˆ†å—æ•°
        try:
            num_chunks = await conn.fetchval("""
                SELECT COUNT(*)
                FROM timescaledb_information.chunks
                WHERE hypertable_name = 'fills'
            """)
        except:
            num_chunks = "N/A"

        print(f"\n   ğŸ“Š Hypertable ä¿¡æ¯:")
        print(f"      è®°å½•æ•°: {new_count:,}")
        print(f"      æ–°è¡¨å¤§å°: {total_size}")
        print(f"      å¤‡ä»½å¤§å°: {backup_size}")
        print(f"      åˆ†å—æ•°: {num_chunks}")

        # 10. æ€§èƒ½æµ‹è¯•
        print("\nğŸ”Ÿ æ€§èƒ½æµ‹è¯•:")
        import time

        # æµ‹è¯•1: æœ€è¿‘æ•°æ®æŸ¥è¯¢
        start = time.time()
        recent = await conn.fetchval("""
            SELECT COUNT(*) FROM fills
            WHERE time > NOW() - INTERVAL '1 day'
        """)
        elapsed = (time.time() - start) * 1000
        print(f"   æœ€è¿‘1å¤©æŸ¥è¯¢: {recent:,} æ¡ ({elapsed:.2f}ms)")

        # æµ‹è¯•2: æ—¶é—´èŒƒå›´æŸ¥è¯¢
        start = time.time()
        week_range = await conn.fetchrow("""
            SELECT
                MIN(time) as min_time,
                MAX(time) as max_time,
                COUNT(*) as count
            FROM fills
            WHERE time > NOW() - INTERVAL '7 days'
        """)
        elapsed = (time.time() - start) * 1000
        print(f"   æœ€è¿‘7å¤©èŒƒå›´æŸ¥è¯¢: {week_range['count']:,} æ¡ ({elapsed:.2f}ms)")

        # 11. æ¸…ç†è¯´æ˜
        print("\n" + "=" * 60)
        print("âœ… TimescaleDB Hypertable è¿ç§»å®Œæˆ")
        print("=" * 60)
        print("\nğŸ“ˆ æ€§èƒ½ä¼˜åŠ¿:")
        print("   â€¢ æ—¶åºæ•°æ®æŸ¥è¯¢æ€§èƒ½æå‡ 10-100x")
        print("   â€¢ è‡ªåŠ¨æ•°æ®å‹ç¼©å’Œåˆ†åŒºç®¡ç†")
        print("   â€¢ é«˜æ•ˆçš„æ—¶é—´èŒƒå›´æŸ¥è¯¢")
        print("   â€¢ æ•°æ®ä¿ç•™ç­–ç•¥è‡ªåŠ¨åŒ–")
        print("\nğŸ“ åç»­æ­¥éª¤:")
        print("   1. âœ“ è¿è¡Œç³»ç»ŸéªŒè¯: python analyze_addresses.py")
        print("   2. âš ï¸  ç¡®è®¤æ— é—®é¢˜ååˆ é™¤å¤‡ä»½è¡¨:")
        print("      DROP TABLE fills_backup;")
        print(f"\n   å¤‡ä»½è¡¨å¤§å°: {backup_size}")
        print("   ä¿ç•™å¤‡ä»½è¡¨å¯ä»¥åœ¨å‡ºç°é—®é¢˜æ—¶å¿«é€Ÿæ¢å¤")

        await conn.close()
        return True

    except Exception as e:
        print(f"\nâŒ è¿ç§»å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

        # å°è¯•æ¢å¤
        print("\nâš ï¸  å°è¯•æ¢å¤...")
        try:
            conn = await asyncpg.connect(**db_config)

            backup_exists = await conn.fetchval("""
                SELECT EXISTS(
                    SELECT 1 FROM information_schema.tables
                    WHERE table_name = 'fills_backup'
                )
            """)

            if backup_exists:
                print("   åˆ é™¤æ–°è¡¨...")
                await conn.execute("DROP TABLE IF EXISTS fills CASCADE")
                print("   æ¢å¤å¤‡ä»½è¡¨...")
                await conn.execute("ALTER TABLE fills_backup RENAME TO fills")
                print("   âœ“ å·²æ¢å¤åˆ°è¿ç§»å‰çŠ¶æ€")

            await conn.close()
        except Exception as recovery_error:
            print(f"   âœ— æ¢å¤å¤±è´¥: {recovery_error}")

        return False


if __name__ == '__main__':
    success = asyncio.run(migrate_to_hypertable())
    exit(0 if success else 1)
