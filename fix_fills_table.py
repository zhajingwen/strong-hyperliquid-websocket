#!/usr/bin/env python3
"""
ä¿®å¤ fills è¡¨çš„ä¸»é”®é—®é¢˜
ç§»é™¤ä¸å¿…è¦çš„ id åˆ—ï¼Œä½¿ç”¨ (time, address, hash) ä½œä¸ºä¸»é”®
"""
import asyncio
import asyncpg
import os
from datetime import datetime


async def fix_fills_table():
    """ä¿®å¤ fills è¡¨ç»“æ„"""
    # æ•°æ®åº“é…ç½®
    db_config = {
        'user': os.getenv('TIMESCALEDB_USER', 'postgres'),
        'password': os.getenv('TIMESCALEDB_PASSWORD', 'postgres'),
        'host': os.getenv('TIMESCALEDB_HOST', '127.0.0.1'),
        'port': int(os.getenv('TIMESCALEDB_PORT', 5432)),
        'database': os.getenv('TIMESCALEDB_DATABASE', 'hyperliquid_analysis'),
        'command_timeout': 600
    }

    print("=" * 60)
    print("ä¿®å¤ fills è¡¨ä¸»é”®ç»“æ„")
    print("=" * 60)

    try:
        # è¿æ¥æ•°æ®åº“
        print("\nğŸ“¡ è¿æ¥æ•°æ®åº“...")
        conn = await asyncpg.connect(**db_config)
        print("   âœ“ è¿æ¥æˆåŠŸ")

        # æ£€æŸ¥å½“å‰çŠ¶æ€
        print("\n1ï¸âƒ£  æ£€æŸ¥å½“å‰çŠ¶æ€...")
        fills_count = await conn.fetchval("SELECT COUNT(*) FROM fills")
        print(f"   fills è¡¨: {fills_count:,} æ¡è®°å½•")

        # æ£€æŸ¥æ˜¯å¦æ˜¯ hypertable
        is_hypertable = await conn.fetchval("""
            SELECT EXISTS(
                SELECT 1 FROM timescaledb_information.hypertables
                WHERE hypertable_name = 'fills'
            )
        """)
        print(f"   æ˜¯å¦ä¸º hypertable: {is_hypertable}")

        # æ£€æŸ¥å½“å‰ä¸»é”®
        pk_columns = await conn.fetch("""
            SELECT a.attname
            FROM pg_index i
            JOIN pg_attribute a ON a.attrelid = i.indrelid
                AND a.attnum = ANY(i.indkey)
            WHERE i.indrelid = 'fills'::regclass
                AND i.indisprimary
            ORDER BY array_position(i.indkey, a.attnum)
        """)
        pk_order = [r['attname'] for r in pk_columns]
        print(f"   å½“å‰ä¸»é”®: ({', '.join(pk_order)})")

        # æ£€æŸ¥æ˜¯å¦æœ‰ id åˆ—
        has_id_column = await conn.fetchval("""
            SELECT EXISTS(
                SELECT 1 FROM information_schema.columns
                WHERE table_name = 'fills' AND column_name = 'id'
            )
        """)
        print(f"   æ˜¯å¦æœ‰ id åˆ—: {has_id_column}")

        # å¦‚æœä¸»é”®æ­£ç¡®ï¼Œæ— éœ€ä¿®å¤
        if set(pk_order) == {'time', 'address', 'hash'} and not has_id_column:
            print("\nâœ… è¡¨ç»“æ„å·²æ­£ç¡®ï¼Œæ— éœ€ä¿®å¤")
            await conn.close()
            return True

        # å¼€å§‹ä¿®å¤
        print("\n2ï¸âƒ£  å¤‡ä»½ç°æœ‰æ•°æ®...")
        await conn.execute("DROP TABLE IF EXISTS fills_old CASCADE")
        await conn.execute("ALTER TABLE fills RENAME TO fills_old")
        print("   âœ“ å·²å¤‡ä»½ä¸º fills_old")

        # åˆ›å»ºæ–°è¡¨
        print("\n3ï¸âƒ£  åˆ›å»ºæ–°è¡¨ç»“æ„...")
        await conn.execute("""
            CREATE TABLE fills (
                address VARCHAR(42) NOT NULL,
                time TIMESTAMPTZ NOT NULL,
                coin VARCHAR(20),
                side VARCHAR(1),
                price DECIMAL(20, 8),
                size DECIMAL(20, 4),
                closed_pnl DECIMAL(20, 8),
                fee DECIMAL(20, 8),
                hash VARCHAR(66),
                PRIMARY KEY (time, address, hash)
            )
        """)
        print("   âœ“ æ–°è¡¨å·²åˆ›å»ºï¼ˆä¸»é”®: time, address, hashï¼‰")

        # å¦‚æœæ˜¯ hypertableï¼Œè½¬æ¢æ–°è¡¨
        if is_hypertable:
            print("\n4ï¸âƒ£  è½¬æ¢ä¸º hypertable...")
            await conn.execute("""
                SELECT create_hypertable('fills', 'time',
                    chunk_time_interval => INTERVAL '7 days',
                    if_not_exists => true
                )
            """)
            print("   âœ“ å·²è½¬æ¢ä¸º hypertable")

        # è¿ç§»æ•°æ®
        print(f"\n5ï¸âƒ£  è¿ç§»æ•°æ®ï¼ˆ{fills_count:,} æ¡è®°å½•ï¼‰...")
        start_time = datetime.now()

        # æ‰¹é‡è¿ç§»
        batch_size = 10000
        offset = 0
        migrated = 0

        while True:
            rows = await conn.fetch(f"""
                SELECT address, time, coin, side, price, size, closed_pnl, fee, hash
                FROM fills_old
                ORDER BY time, address
                LIMIT {batch_size} OFFSET {offset}
            """)

            if not rows:
                break

            # æ‰¹é‡æ’å…¥ï¼ˆè·³è¿‡é‡å¤è®°å½•ï¼‰
            try:
                await conn.executemany("""
                    INSERT INTO fills (address, time, coin, side, price, size, closed_pnl, fee, hash)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                    ON CONFLICT (time, address, hash) DO NOTHING
                """, [
                    (r['address'], r['time'], r['coin'], r['side'],
                     r['price'], r['size'], r['closed_pnl'], r['fee'], r['hash'])
                    for r in rows
                ])
                migrated += len(rows)
            except Exception as e:
                print(f"\n   âš ï¸  æ‰¹æ¬¡æ’å…¥å¤±è´¥: {e}")
                # å°è¯•é€æ¡æ’å…¥
                for r in rows:
                    try:
                        await conn.execute("""
                            INSERT INTO fills (address, time, coin, side, price, size, closed_pnl, fee, hash)
                            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                            ON CONFLICT (time, address, hash) DO NOTHING
                        """, r['address'], r['time'], r['coin'], r['side'],
                            r['price'], r['size'], r['closed_pnl'], r['fee'], r['hash'])
                        migrated += 1
                    except Exception as inner_e:
                        print(f"\n   âš ï¸  è·³è¿‡è®°å½•: {r['address'][:10]}... @ {r['time']} - {inner_e}")

            offset += batch_size
            progress = min(migrated * 100 // fills_count, 100) if fills_count > 0 else 100
            print(f"   è¿›åº¦: {migrated:,} / {fills_count:,} ({progress}%)", end='\r')

            if len(rows) < batch_size:
                break

        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"\n   âœ“ æ•°æ®è¿ç§»å®Œæˆ: {migrated:,} æ¡ ({elapsed:.1f}ç§’)")

        # éªŒè¯æ•°æ®
        print("\n6ï¸âƒ£  éªŒè¯æ•°æ®...")
        new_count = await conn.fetchval("SELECT COUNT(*) FROM fills")
        print(f"   æ–°è¡¨è®°å½•æ•°: {new_count:,}")
        print(f"   åŸè¡¨è®°å½•æ•°: {fills_count:,}")

        if new_count > 0:
            print("   âœ“ æ•°æ®è¿ç§»æˆåŠŸ")
        else:
            print("   âš ï¸  è­¦å‘Š: æ–°è¡¨ä¸ºç©º")

        # åˆ›å»ºç´¢å¼•
        print("\n7ï¸âƒ£  åˆ›å»ºç´¢å¼•...")
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_fills_address_time
            ON fills(address, time DESC)
        """)
        print("   âœ“ ç´¢å¼•å·²åˆ›å»º")

        # æœ€ç»ˆçŠ¶æ€
        print("\n8ï¸âƒ£  æœ€ç»ˆçŠ¶æ€:")
        new_pk = await conn.fetch("""
            SELECT a.attname
            FROM pg_index i
            JOIN pg_attribute a ON a.attrelid = i.indrelid
                AND a.attnum = ANY(i.indkey)
            WHERE i.indrelid = 'fills'::regclass
                AND i.indisprimary
            ORDER BY array_position(i.indkey, a.attnum)
        """)
        new_pk_order = [r['attname'] for r in new_pk]
        print(f"   æ–°ä¸»é”®: ({', '.join(new_pk_order)})")
        print(f"   è®°å½•æ•°: {new_count:,}")

        # æ¸…ç†è¯´æ˜
        print("\n" + "=" * 60)
        print("âœ… ä¿®å¤å®Œæˆ")
        print("=" * 60)
        print("\nğŸ“ åç»­æ­¥éª¤:")
        print("   1. âœ“ æµ‹è¯•ç³»ç»Ÿ: python analyze_addresses.py --concurrent 1")
        print("   2. âš ï¸  ç¡®è®¤æ— é—®é¢˜ååˆ é™¤å¤‡ä»½è¡¨:")
        print("      DROP TABLE fills_old;")
        print("\n   å¤‡ä»½è¡¨ä¿ç•™ç”¨äºå¿«é€Ÿæ¢å¤")

        await conn.close()
        return True

    except Exception as e:
        print(f"\nâŒ ä¿®å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

        # å°è¯•æ¢å¤
        print("\nâš ï¸  å°è¯•æ¢å¤...")
        try:
            conn = await asyncpg.connect(**db_config)

            old_exists = await conn.fetchval("""
                SELECT EXISTS(
                    SELECT 1 FROM information_schema.tables
                    WHERE table_name = 'fills_old'
                )
            """)

            if old_exists:
                print("   åˆ é™¤æ–°è¡¨...")
                await conn.execute("DROP TABLE IF EXISTS fills CASCADE")
                print("   æ¢å¤å¤‡ä»½è¡¨...")
                await conn.execute("ALTER TABLE fills_old RENAME TO fills")
                print("   âœ“ å·²æ¢å¤åˆ°ä¿®å¤å‰çŠ¶æ€")

            await conn.close()
        except Exception as recovery_error:
            print(f"   âœ— æ¢å¤å¤±è´¥: {recovery_error}")

        return False


if __name__ == '__main__':
    success = asyncio.run(fix_fills_table())
    exit(0 if success else 1)
