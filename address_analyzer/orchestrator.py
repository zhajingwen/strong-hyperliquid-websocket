"""
ä¸»æ§åˆ¶å™¨ - åè°ƒæ‰€æœ‰æ¨¡å—ï¼Œå®ç°å®Œæ•´å·¥ä½œæµ
"""

import asyncio
import logging
from typing import List, Optional
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn

from .log_parser import LogParser
from .api_client import HyperliquidAPIClient
from .metrics_engine import MetricsEngine, AddressMetrics
from .data_store import DataStore, get_store
from .output_renderer import OutputRenderer

logger = logging.getLogger(__name__)


class Orchestrator:
    """ä¸»æ§åˆ¶å™¨ - åè°ƒæ•´ä¸ªåˆ†æå·¥ä½œæµ"""

    def __init__(
        self,
        log_path: str = "trades.log",
        force_refresh: bool = False,
        max_concurrent: int = 10,
        rate_limit: int = 50
    ):
        """
        åˆå§‹åŒ–ä¸»æ§åˆ¶å™¨

        Args:
            log_path: trades.log è·¯å¾„
            force_refresh: å¼ºåˆ¶åˆ·æ–°ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            rate_limit: APIé€Ÿç‡é™åˆ¶
        """
        self.log_path = log_path
        self.force_refresh = force_refresh

        # åˆå§‹åŒ–ç»„ä»¶
        self.log_parser = LogParser(log_path)
        self.store: Optional[DataStore] = None
        self.api_client: Optional[HyperliquidAPIClient] = None
        self.metrics_engine = MetricsEngine()
        self.renderer = OutputRenderer()

        self.max_concurrent = max_concurrent
        self.rate_limit = rate_limit

    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“å’ŒAPIå®¢æˆ·ç«¯"""
        logger.info("========== å¼€å§‹åˆå§‹åŒ– ==========")
        logger.info("åˆå§‹åŒ–æ•°æ®å­˜å‚¨...")
        self.store = get_store()
        await self.store.connect(max_connections=self.max_concurrent * 2)
        logger.info(f"æ•°æ®åº“è¿æ¥æ± å·²å»ºç«‹: æœ€å¤§è¿æ¥æ•° {self.max_concurrent * 2}")

        logger.info("åˆå§‹åŒ–APIå®¢æˆ·ç«¯...")
        self.api_client = HyperliquidAPIClient(
            store=self.store,
            max_concurrent=self.max_concurrent,
            rate_limit=self.rate_limit
        )
        logger.info(f"APIå®¢æˆ·ç«¯å·²åˆå§‹åŒ–: æœ€å¤§å¹¶å‘ {self.max_concurrent}, é€Ÿç‡é™åˆ¶ {self.rate_limit} req/s")
        logger.info("========== åˆå§‹åŒ–å®Œæˆ ==========\n")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("å¼€å§‹æ¸…ç†èµ„æº...")
        if self.store:
            await self.store.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

    async def run(
        self,
        output_terminal: bool = True,
        output_html: bool = True,
        html_path: str = "output/analysis_report.html",
        terminal_path: Optional[str] = None,
        top_n: int = 50
    ) -> List[AddressMetrics]:
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹

        Args:
            output_terminal: è¾“å‡ºç»ˆç«¯è¡¨æ ¼
            output_html: è¾“å‡ºHTMLæŠ¥å‘Š
            html_path: HTMLæŠ¥å‘Šè·¯å¾„
            terminal_path: ç»ˆç«¯è¾“å‡ºä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            top_n: ç»ˆç«¯æ˜¾ç¤ºå‰Nä¸ªåœ°å€

        Returns:
            æŒ‡æ ‡åˆ—è¡¨
        """
        try:
            # 1. è§£ææ—¥å¿—
            self.renderer.console.print("\n[bold cyan]æ­¥éª¤ 1/5:[/bold cyan] è§£æäº¤æ˜“æ—¥å¿—...")
            logger.info(f"æ­¥éª¤ 1/5: å¼€å§‹è§£æäº¤æ˜“æ—¥å¿—æ–‡ä»¶: {self.log_path}")
            address_stats = self.log_parser.parse()
            addresses = list(address_stats.keys())
            logger.info(f"æ­¥éª¤ 1/5 å®Œæˆ: è§£æåˆ° {len(addresses)} ä¸ªå”¯ä¸€åœ°å€")
            self.renderer.console.print(f"âœ… è§£æåˆ° [bold]{len(addresses)}[/bold] ä¸ªå”¯ä¸€åœ°å€\n")

            # 2. æ›´æ–°åœ°å€è¡¨
            self.renderer.console.print("[bold cyan]æ­¥éª¤ 2/5:[/bold cyan] æ›´æ–°åœ°å€æ•°æ®åº“...")
            logger.info(f"æ­¥éª¤ 2/5: å¼€å§‹æ›´æ–°åœ°å€æ•°æ®åº“ï¼Œå…± {len(addresses)} ä¸ªåœ°å€")
            await self.store.upsert_addresses([
                {
                    'address': addr,
                    'taker_count': stats['taker_count'],
                    'maker_count': stats['maker_count']
                }
                for addr, stats in address_stats.items()
            ])
            logger.info("æ­¥éª¤ 2/5 å®Œæˆ: åœ°å€æ•°æ®åº“å·²æ›´æ–°")
            self.renderer.console.print("âœ… åœ°å€æ•°æ®åº“å·²æ›´æ–°\n")

            # 3. è·å–å¾…å¤„ç†åœ°å€
            if self.force_refresh:
                pending_addresses = addresses
                logger.info(f"å¼ºåˆ¶åˆ·æ–°æ¨¡å¼: å°†é‡æ–°è·å–æ‰€æœ‰ {len(addresses)} ä¸ªåœ°å€çš„æ•°æ®")
                self.renderer.console.print("[yellow]âš ï¸  å¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼šå°†é‡æ–°è·å–æ‰€æœ‰åœ°å€æ•°æ®[/yellow]\n")
            else:
                pending_addresses = await self.store.get_pending_addresses()
                if not pending_addresses:
                    pending_addresses = addresses
                    logger.info(f"æœªæ‰¾åˆ°å¾…å¤„ç†åœ°å€ï¼Œå°†è·å–æ‰€æœ‰ {len(addresses)} ä¸ªåœ°å€çš„æ•°æ®")
                    self.renderer.console.print("[yellow]âš ï¸  æœªæ‰¾åˆ°å¾…å¤„ç†åœ°å€ï¼Œå°†è·å–æ‰€æœ‰åœ°å€æ•°æ®[/yellow]\n")
                else:
                    logger.info(f"å‘ç° {len(pending_addresses)} ä¸ªå¾…å¤„ç†åœ°å€ï¼ˆå…± {len(addresses)} ä¸ªåœ°å€ï¼‰")
                    self.renderer.console.print(f"ğŸ“‹ å‘ç° [bold]{len(pending_addresses)}[/bold] ä¸ªå¾…å¤„ç†åœ°å€\n")

            # 4. æ‰¹é‡è·å–APIæ•°æ®
            self.renderer.console.print(f"[bold cyan]æ­¥éª¤ 3/5:[/bold cyan] è·å–APIæ•°æ®ï¼ˆ{len(pending_addresses)} ä¸ªåœ°å€ï¼‰...")
            logger.info(f"æ­¥éª¤ 3/5: å¼€å§‹è·å–APIæ•°æ®ï¼Œå…± {len(pending_addresses)} ä¸ªå¾…å¤„ç†åœ°å€")

            # è¿›åº¦è®¡æ•°å™¨
            processed_count = 0
            success_count = 0
            failed_count = 0

            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                TimeRemainingColumn(),
                console=self.renderer.console
            ) as progress:
                task = progress.add_task("æ­£åœ¨è·å–æ•°æ®...", total=len(pending_addresses))

                async def process_address(addr: str, index: int) -> Optional[dict]:
                    """å¤„ç†å•ä¸ªåœ°å€"""
                    nonlocal processed_count, success_count, failed_count

                    try:
                        logger.info(f"[{index}/{len(pending_addresses)}] å¼€å§‹å¤„ç†åœ°å€: {addr}")

                        # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
                        await self.store.update_processing_status(addr, 'processing')

                        # è·å–æ•°æ®
                        data = await self.api_client.fetch_address_data(addr, save_to_db=True)

                        # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
                        await self.store.update_processing_status(addr, 'completed')

                        # æ ‡è®°åœ°å€æ•°æ®å·²å®Œæ•´è·å–
                        await self.store.mark_address_complete(addr)

                        processed_count += 1
                        success_count += 1
                        progress.advance(task)

                        logger.info(
                            f"[{index}/{len(pending_addresses)}] âœ… æˆåŠŸå¤„ç†: {addr} "
                            f"(å·²å¤„ç†: {processed_count}, æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count})"
                        )
                        return data

                    except Exception as e:
                        processed_count += 1
                        failed_count += 1
                        logger.error(
                            f"[{index}/{len(pending_addresses)}] âŒ å¤„ç†å¤±è´¥: {addr[:10]}... - {e} "
                            f"(å·²å¤„ç†: {processed_count}, æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count})"
                        )
                        await self.store.update_processing_status(addr, 'failed', str(e))
                        progress.advance(task)
                        return None

                # å¹¶å‘å¤„ç†ï¼ˆä¸ºæ¯ä¸ªåœ°å€åˆ†é…ç´¢å¼•ï¼‰
                tasks = [process_address(addr, idx + 1) for idx, addr in enumerate(pending_addresses)]
                results = await asyncio.gather(*tasks, return_exceptions=True)

                # è¿‡æ»¤å¤±è´¥ç»“æœ
                successful_results = [r for r in results if r and not isinstance(r, Exception)]

            logger.info(f"æ­¥éª¤ 3/5 å®Œæˆ: å…±å¤„ç† {processed_count} ä¸ªåœ°å€ï¼ŒæˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª")

            self.renderer.console.print(f"âœ… æˆåŠŸè·å– [bold]{len(successful_results)}[/bold] ä¸ªåœ°å€çš„æ•°æ®\n")

            # API ç»Ÿè®¡
            stats = self.api_client.get_stats()
            logger.info(
                f"API ç»Ÿè®¡: æ€»è¯·æ±‚ {stats['total_requests']} æ¬¡, "
                f"ç¼“å­˜å‘½ä¸­ {stats['cache_hits']} æ¬¡ (å‘½ä¸­ç‡: {stats['cache_hit_rate']:.1%}), "
                f"APIé”™è¯¯ {stats['api_errors']} æ¬¡"
            )
            self.renderer.console.print(
                f"[dim]API ç»Ÿè®¡: è¯·æ±‚ {stats['total_requests']} æ¬¡, "
                f"ç¼“å­˜å‘½ä¸­ {stats['cache_hits']} æ¬¡ ({stats['cache_hit_rate']:.1%}), "
                f"é”™è¯¯ {stats['api_errors']} æ¬¡[/dim]\n"
            )

            # 5. è®¡ç®—æŒ‡æ ‡
            self.renderer.console.print(f"[bold cyan]æ­¥éª¤ 4/5:[/bold cyan] è®¡ç®—äº¤æ˜“æŒ‡æ ‡...")
            logger.info(f"æ­¥éª¤ 4/5: å¼€å§‹è®¡ç®—äº¤æ˜“æŒ‡æ ‡ï¼Œå…± {len(addresses)} ä¸ªåœ°å€")

            all_metrics = []
            calculated_count = 0
            qualified_count = 0
            skipped_no_fills = 0
            skipped_filters = 0

            for idx, addr in enumerate(addresses, 1):
                logger.info(f"[{idx}/{len(addresses)}] è®¡ç®—æŒ‡æ ‡: {addr}")

                # ä»æ•°æ®åº“è¯»å–äº¤æ˜“è®°å½•
                fills = await self.store.get_fills(addr)
                if not fills:
                    skipped_no_fills += 1
                    logger.warning(f"[{idx}/{len(addresses)}] åœ°å€æ— äº¤æ˜“è®°å½•: {addr[:10]}... (è·³è¿‡)")
                    continue

                # è·å–è´¦æˆ·çŠ¶æ€ï¼ˆä»ç¼“å­˜ï¼‰
                state = await self.store.get_api_cache(f"user_state:{addr}")

                # è·å– Spot è´¦æˆ·çŠ¶æ€ï¼ˆä»ç¼“å­˜ï¼‰
                spot_state = await self.store.get_api_cache(f"spot_state:{addr}")

                # è·å–å‡ºå…¥é‡‘ç»Ÿè®¡
                transfer_stats = await self.store.get_net_deposits(addr)

                # è®¡ç®—æŒ‡æ ‡ï¼ˆä¼ å…¥æ–°å‚æ•°ï¼ŒåŒ…æ‹¬ spot_stateï¼‰
                metrics = self.metrics_engine.calculate_metrics(
                    address=addr,
                    fills=fills,
                    state=state,
                    transfer_data=transfer_stats,
                    spot_state=spot_state
                )

                # ä¿å­˜åˆ°ç¼“å­˜
                await self.store.save_metrics(addr, {
                    'total_trades': metrics.total_trades,
                    'win_rate': metrics.win_rate,
                    'sharpe_ratio': metrics.sharpe_ratio,
                    'total_pnl': metrics.total_pnl,
                    'account_value': metrics.account_value,
                    'max_drawdown': metrics.max_drawdown
                })

                calculated_count += 1

                # ç­›é€‰æ¡ä»¶
                if metrics.total_pnl < 0:
                    skipped_filters += 1
                    logger.warning(f"[{idx}/{len(addresses)}] åœ°å€ {addr[:10]}... æ€»PNL<0ï¼Œè·³è¿‡æŠ¥å‘Šè¾“å‡º")
                    continue
                if metrics.win_rate < 60:
                    skipped_filters += 1
                    logger.warning(f"[{idx}/{len(addresses)}] åœ°å€ {addr[:10]}... èƒœç‡<60%ï¼Œè·³è¿‡æŠ¥å‘Šè¾“å‡º")
                    continue

                qualified_count += 1
                all_metrics.append(metrics)
                logger.info(
                    f"[{idx}/{len(addresses)}] âœ… åœ°å€ç¬¦åˆæ¡ä»¶: {addr[:10]}... "
                    f"(PNL: {metrics.total_pnl:.2f}, èƒœç‡: {metrics.win_rate:.1f}%)"
                )

            logger.info(
                f"æ­¥éª¤ 4/5 å®Œæˆ: å…±è®¡ç®— {calculated_count} ä¸ªåœ°å€ï¼Œ"
                f"ç¬¦åˆæ¡ä»¶ {qualified_count} ä¸ªï¼Œ"
                f"æ— äº¤æ˜“è®°å½• {skipped_no_fills} ä¸ªï¼Œ"
                f"ä¸ç¬¦åˆç­›é€‰æ¡ä»¶ {skipped_filters} ä¸ª"
            )
            self.renderer.console.print(f"âœ… è®¡ç®—å®Œæˆ [bold]{len(all_metrics)}[/bold] ä¸ªåœ°å€çš„æŒ‡æ ‡\n")

            # 6. è¾“å‡ºæŠ¥å‘Š
            self.renderer.console.print("[bold cyan]æ­¥éª¤ 5/5:[/bold cyan] ç”ŸæˆæŠ¥å‘Š...\n")
            logger.info(f"æ­¥éª¤ 5/5: å¼€å§‹ç”ŸæˆæŠ¥å‘Šï¼Œå…± {len(all_metrics)} ä¸ªç¬¦åˆæ¡ä»¶çš„åœ°å€")

            if output_terminal:
                logger.info(f"ç”Ÿæˆç»ˆç«¯æŠ¥å‘Š: æ˜¾ç¤ºå‰ {top_n} ä¸ªåœ°å€")
                if terminal_path:
                    logger.info(f"ç»ˆç«¯æŠ¥å‘Šå°†ä¿å­˜åˆ°: {terminal_path}")
                self.renderer.render_terminal(all_metrics, top_n=top_n, save_path=terminal_path)

            if output_html and all_metrics:
                logger.info(f"ç”ŸæˆHTMLæŠ¥å‘Š: {html_path}")
                self.renderer.render_html(all_metrics, output_path=html_path)
                logger.info(f"HTMLæŠ¥å‘Šå·²ä¿å­˜: {html_path}")

            logger.info(
                f"========== åˆ†æå®Œæˆ ==========\n"
                f"æ€»åœ°å€æ•°: {len(addresses)}\n"
                f"å¾…å¤„ç†åœ°å€: {len(pending_addresses)}\n"
                f"æˆåŠŸè·å–æ•°æ®: {success_count}\n"
                f"è·å–å¤±è´¥: {failed_count}\n"
                f"è®¡ç®—æŒ‡æ ‡: {calculated_count}\n"
                f"ç¬¦åˆç­›é€‰æ¡ä»¶: {qualified_count}\n"
                f"æœ€ç»ˆæŠ¥å‘Šåœ°å€æ•°: {len(all_metrics)}\n"
                f"=============================="
            )
            self.renderer.console.print("\n[bold green]âœ¨ åˆ†æå®Œæˆï¼[/bold green]\n")

            return all_metrics

        except Exception as e:
            logger.error(f"åˆ†ææµç¨‹å¤±è´¥: {e}", exc_info=True)
            self.renderer.console.print(f"\n[bold red]âŒ é”™è¯¯: {e}[/bold red]\n")
            raise


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='Hyperliquid äº¤æ˜“åœ°å€åˆ†æå·¥å…·')
    parser.add_argument('--log-path', default='trades.log', help='trades.log è·¯å¾„')
    parser.add_argument('--force-refresh', action='store_true', help='å¼ºåˆ¶åˆ·æ–°ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰')
    parser.add_argument('--output', choices=['terminal', 'html', 'both'], default='both', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--html-path', default='output/analysis_report.html', help='HTMLæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--terminal-path', help='ç»ˆç«¯è¾“å‡ºä¿å­˜è·¯å¾„')
    parser.add_argument('--top-n', type=int, default=50, help='ç»ˆç«¯æ˜¾ç¤ºå‰Nä¸ªåœ°å€')
    parser.add_argument('--concurrent', type=int, default=10, help='æœ€å¤§å¹¶å‘æ•°')
    parser.add_argument('--rate-limit', type=int, default=50, help='APIé€Ÿç‡é™åˆ¶ï¼ˆè¯·æ±‚/ç§’ï¼‰')

    args = parser.parse_args()

    # åˆå§‹åŒ–æ§åˆ¶å™¨
    orchestrator = Orchestrator(
        log_path=args.log_path,
        force_refresh=args.force_refresh,
        max_concurrent=args.concurrent,
        rate_limit=args.rate_limit
    )

    try:
        await orchestrator.initialize()

        # è¿è¡Œåˆ†æ
        await orchestrator.run(
            output_terminal=args.output in ('terminal', 'both'),
            output_html=args.output in ('html', 'both'),
            html_path=args.html_path,
            terminal_path=args.terminal_path,
            top_n=args.top_n
        )

    finally:
        await orchestrator.cleanup()


if __name__ == '__main__':
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    asyncio.run(main())
